{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2afb641",
   "metadata": {},
   "source": [
    "# Intitial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecbc3042",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "path = r\"C:\\Users\\athen\\Documents\\GitHub\\TCD_Dissertation\\archive\\raw_forecast_logs.tsv\"\n",
    "chunksize = 500000\n",
    "cols = ['DateTime', 'Line', 'Origin', 'Direction', 'Destination', 'Due in', 'Minutes', 'Status Message']\n",
    "\n",
    "snapshot_counts_chunks = []\n",
    "\n",
    "for chunk in pd.read_csv(path, sep='\\t', header=None, names=cols, \n",
    "                         chunksize=chunksize, on_bad_lines='skip', low_memory=False):\n",
    "\n",
    "    chunk['DateTime'] = pd.to_datetime(chunk['DateTime'], format='%m/%d/%Y %H:%M:%S', errors='coerce')\n",
    "    chunk['Minutes'] = pd.to_numeric(chunk['Minutes'], errors='coerce')\n",
    "    chunk.dropna(subset=['DateTime', 'Minutes'], inplace=True)\n",
    "    # Only append if chunk still has rows after filtering\n",
    "    if not chunk.empty:\n",
    "        snapshot_counts_chunks.append(chunk)\n",
    "\n",
    "# Combine final data\n",
    "df = pd.concat(snapshot_counts_chunks, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa86e9f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Destination      BEL     BLA       BRI       BRO      CON  DOM     HEU  \\\n",
      "Direction                                                                \n",
      "Inbound to   1941473  148501         0  23485371  8897689    0       0   \n",
      "Outbound to        0       0  27205800         0        0  465  249911   \n",
      "\n",
      "Destination       PAR     RED       SAG       SAN   STS       TAL       TPT  \n",
      "Direction                                                                    \n",
      "Inbound to   16348033       0         0         0  3851         0  28771267  \n",
      "Outbound to         0  342470  17067873  13025550     0  23399466         0  \n"
     ]
    }
   ],
   "source": [
    "counts = df[[\"Origin\", \"Destination\", \"Direction\", \"Status Message\"]]\n",
    "direction_counts = df.groupby([\"Direction\", \"Destination\"]).size().unstack(fill_value=0)\n",
    "print(direction_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d616669",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc90859b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ServiceDay'] = pd.to_datetime(df['ServiceDay'])\n",
    "\n",
    "pre_covid = df[(df['ServiceDay'] >= '2020-01-20') & (df['ServiceDay'] < '2020-03-21')]\n",
    "covid_lockdown = df[(df['ServiceDay'] >= '2020-03-21') & (df['ServiceDay'] <= '2021-05-31')]\n",
    "covid_recovery = df[(df['ServiceDay'] >= '2021-06-01') & (df['ServiceDay'] <= '2022-01-21')]\n",
    "post_covid = df[(df['ServiceDay'] >= '2022-01-22') & (df['ServiceDay'] <= '2022-10-22')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1171b5a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-COVID: 10,536,052 rows\n",
      "COVID Lockdown: 70,119,473 rows\n",
      "COVID Recovery: 35,917,583 rows\n",
      "Post-COVID: 43,612,616 rows\n"
     ]
    }
   ],
   "source": [
    "print(f\"Pre-COVID: {len(pre_covid):,} rows\")\n",
    "print(f\"COVID Lockdown: {len(covid_lockdown):,} rows\")\n",
    "print(f\"COVID Recovery: {len(covid_recovery):,} rows\")\n",
    "print(f\"Post-COVID: {len(post_covid):,} rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2b3e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "ouput_dir = r\"C:\\Users\\athen\\Documents\\GitHub\\TCD_Dissertation\\archive\\periods\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "pre_covid.to_csv(f\"{output_dir}/pre_covid.csv\", index=False)\n",
    "covid_lockdown.to_csv(f\"{output_dir}/covid_lockdown.csv\", index=False)\n",
    "covid_recovery.to_csv(f\"{output_dir}/covid_recovery.csv\", index=False)\n",
    "post_covid.to_csv(f\"{output_dir}/post_covid.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c629b087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended 500,000 rows to pre_covid_january_2020.csv\n",
      "Appended 500,000 rows to pre_covid_january_2020.csv\n",
      "Appended 500,000 rows to pre_covid_january_2020.csv\n",
      "Appended 500,000 rows to pre_covid_january_2020.csv\n",
      "Appended 337,732 rows to pre_covid_february_2020.csv\n",
      "Appended 162,268 rows to pre_covid_january_2020.csv\n",
      "Appended 500,000 rows to pre_covid_february_2020.csv\n",
      "Appended 500,000 rows to pre_covid_february_2020.csv\n",
      "Appended 500,000 rows to pre_covid_february_2020.csv\n",
      "Appended 500,000 rows to pre_covid_february_2020.csv\n",
      "Appended 500,000 rows to pre_covid_february_2020.csv\n",
      "Appended 500,000 rows to pre_covid_february_2020.csv\n",
      "Appended 500,000 rows to pre_covid_february_2020.csv\n",
      "Appended 500,000 rows to pre_covid_february_2020.csv\n",
      "Appended 500,000 rows to pre_covid_february_2020.csv\n",
      "Appended 177,209 rows to pre_covid_february_2020.csv\n",
      "Appended 322,791 rows to pre_covid_march_2020.csv\n",
      "Appended 500,000 rows to pre_covid_march_2020.csv\n",
      "Appended 500,000 rows to pre_covid_march_2020.csv\n",
      "Appended 500,000 rows to pre_covid_march_2020.csv\n",
      "Appended 500,000 rows to pre_covid_march_2020.csv\n",
      "Appended 500,000 rows to pre_covid_march_2020.csv\n",
      "Appended 500,000 rows to pre_covid_march_2020.csv\n",
      "Appended 36,052 rows to pre_covid_march_2020.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# File path and output directory\n",
    "file_path = r\"C:\\Users\\athen\\Documents\\GitHub\\TCD_Dissertation\\archive\\periods\\precovid\\pre_covid.csv\"\n",
    "output_dir = r\"C:\\Users\\athen\\Documents\\GitHub\\TCD_Dissertation\\archive\\periods\\precovid\\months\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "chunksize = 500_000\n",
    "written_files = set()\n",
    "\n",
    "# Process and save each chunk individually\n",
    "for chunk in pd.read_csv(file_path, chunksize=chunksize, parse_dates=[\"DateTime\", \"ServiceDay\"]):\n",
    "    chunk['Month'] = chunk['ServiceDay'].dt.strftime('%B').str.lower()\n",
    "    chunk['Year'] = chunk['ServiceDay'].dt.year\n",
    "\n",
    "    for (year, month), group in chunk.groupby(['Year', 'Month']):\n",
    "        filename = f\"pre_covid_{month}_{year}.csv\"\n",
    "        filepath = os.path.join(output_dir, filename)\n",
    "\n",
    "        write_header = filename not in written_files\n",
    "        group.to_csv(filepath, mode='a', header=write_header, index=False)\n",
    "        written_files.add(filename)\n",
    "\n",
    "        print(f\"Appended {len(group):,} rows to {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31bc739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended 500,000 rows to lockdown_march_2020.csv\n",
      "Appended 500,000 rows to lockdown_march_2020.csv\n",
      "Appended 500,000 rows to lockdown_march_2020.csv\n",
      "Appended 219,207 rows to lockdown_april_2020.csv\n",
      "Appended 280,793 rows to lockdown_march_2020.csv\n",
      "Appended 500,000 rows to lockdown_april_2020.csv\n",
      "Appended 500,000 rows to lockdown_april_2020.csv\n",
      "Appended 500,000 rows to lockdown_april_2020.csv\n",
      "Appended 500,000 rows to lockdown_april_2020.csv\n",
      "Appended 500,000 rows to lockdown_april_2020.csv\n",
      "Appended 500,000 rows to lockdown_april_2020.csv\n",
      "Appended 500,000 rows to lockdown_april_2020.csv\n",
      "Appended 500,000 rows to lockdown_april_2020.csv\n",
      "Appended 500,000 rows to lockdown_april_2020.csv\n",
      "Appended 145,279 rows to lockdown_april_2020.csv\n",
      "Appended 354,721 rows to lockdown_may_2020.csv\n",
      "Appended 500,000 rows to lockdown_may_2020.csv\n",
      "Appended 500,000 rows to lockdown_may_2020.csv\n",
      "Appended 500,000 rows to lockdown_may_2020.csv\n",
      "Appended 500,000 rows to lockdown_may_2020.csv\n",
      "Appended 500,000 rows to lockdown_may_2020.csv\n",
      "Appended 500,000 rows to lockdown_may_2020.csv\n",
      "Appended 500,000 rows to lockdown_may_2020.csv\n",
      "Appended 500,000 rows to lockdown_may_2020.csv\n",
      "Appended 500,000 rows to lockdown_may_2020.csv\n",
      "Appended 484,969 rows to lockdown_june_2020.csv\n",
      "Appended 15,031 rows to lockdown_may_2020.csv\n",
      "Appended 500,000 rows to lockdown_june_2020.csv\n",
      "Appended 500,000 rows to lockdown_june_2020.csv\n",
      "Appended 500,000 rows to lockdown_june_2020.csv\n",
      "Appended 500,000 rows to lockdown_june_2020.csv\n",
      "Appended 500,000 rows to lockdown_june_2020.csv\n",
      "Appended 500,000 rows to lockdown_june_2020.csv\n",
      "Appended 500,000 rows to lockdown_june_2020.csv\n",
      "Appended 500,000 rows to lockdown_june_2020.csv\n",
      "Appended 118,795 rows to lockdown_july_2020.csv\n",
      "Appended 381,205 rows to lockdown_june_2020.csv\n",
      "Appended 500,000 rows to lockdown_july_2020.csv\n",
      "Appended 500,000 rows to lockdown_july_2020.csv\n",
      "Appended 500,000 rows to lockdown_july_2020.csv\n",
      "Appended 500,000 rows to lockdown_july_2020.csv\n",
      "Appended 500,000 rows to lockdown_july_2020.csv\n",
      "Appended 500,000 rows to lockdown_july_2020.csv\n",
      "Appended 500,000 rows to lockdown_july_2020.csv\n",
      "Appended 500,000 rows to lockdown_july_2020.csv\n",
      "Appended 500,000 rows to lockdown_july_2020.csv\n",
      "Appended 500,000 rows to lockdown_july_2020.csv\n",
      "Appended 463,347 rows to lockdown_august_2020.csv\n",
      "Appended 36,653 rows to lockdown_july_2020.csv\n",
      "Appended 500,000 rows to lockdown_august_2020.csv\n",
      "Appended 500,000 rows to lockdown_august_2020.csv\n",
      "Appended 500,000 rows to lockdown_august_2020.csv\n",
      "Appended 500,000 rows to lockdown_august_2020.csv\n",
      "Appended 500,000 rows to lockdown_august_2020.csv\n",
      "Appended 500,000 rows to lockdown_august_2020.csv\n",
      "Appended 500,000 rows to lockdown_august_2020.csv\n",
      "Appended 500,000 rows to lockdown_august_2020.csv\n",
      "Appended 453,248 rows to lockdown_august_2020.csv\n",
      "Appended 46,752 rows to lockdown_september_2020.csv\n",
      "Appended 500,000 rows to lockdown_september_2020.csv\n",
      "Appended 500,000 rows to lockdown_september_2020.csv\n",
      "Appended 500,000 rows to lockdown_september_2020.csv\n",
      "Appended 500,000 rows to lockdown_september_2020.csv\n",
      "Appended 500,000 rows to lockdown_september_2020.csv\n",
      "Appended 500,000 rows to lockdown_september_2020.csv\n",
      "Appended 500,000 rows to lockdown_september_2020.csv\n",
      "Appended 500,000 rows to lockdown_september_2020.csv\n",
      "Appended 500,000 rows to lockdown_september_2020.csv\n",
      "Appended 132,057 rows to lockdown_october_2020.csv\n",
      "Appended 367,943 rows to lockdown_september_2020.csv\n",
      "Appended 500,000 rows to lockdown_october_2020.csv\n",
      "Appended 500,000 rows to lockdown_october_2020.csv\n",
      "Appended 500,000 rows to lockdown_october_2020.csv\n",
      "Appended 500,000 rows to lockdown_october_2020.csv\n",
      "Appended 500,000 rows to lockdown_october_2020.csv\n",
      "Appended 500,000 rows to lockdown_october_2020.csv\n",
      "Appended 500,000 rows to lockdown_october_2020.csv\n",
      "Appended 500,000 rows to lockdown_october_2020.csv\n",
      "Appended 500,000 rows to lockdown_october_2020.csv\n",
      "Appended 10,216 rows to lockdown_november_2020.csv\n",
      "Appended 489,784 rows to lockdown_october_2020.csv\n",
      "Appended 500,000 rows to lockdown_november_2020.csv\n",
      "Appended 500,000 rows to lockdown_november_2020.csv\n",
      "Appended 500,000 rows to lockdown_november_2020.csv\n",
      "Appended 500,000 rows to lockdown_november_2020.csv\n",
      "Appended 500,000 rows to lockdown_november_2020.csv\n",
      "Appended 500,000 rows to lockdown_november_2020.csv\n",
      "Appended 500,000 rows to lockdown_november_2020.csv\n",
      "Appended 500,000 rows to lockdown_november_2020.csv\n",
      "Appended 500,000 rows to lockdown_november_2020.csv\n",
      "Appended 189,255 rows to lockdown_december_2020.csv\n",
      "Appended 310,745 rows to lockdown_november_2020.csv\n",
      "Appended 500,000 rows to lockdown_december_2020.csv\n",
      "Appended 500,000 rows to lockdown_december_2020.csv\n",
      "Appended 500,000 rows to lockdown_december_2020.csv\n",
      "Appended 500,000 rows to lockdown_december_2020.csv\n",
      "Appended 500,000 rows to lockdown_december_2020.csv\n",
      "Appended 500,000 rows to lockdown_december_2020.csv\n",
      "Appended 500,000 rows to lockdown_december_2020.csv\n",
      "Appended 500,000 rows to lockdown_december_2020.csv\n",
      "Appended 431,570 rows to lockdown_december_2020.csv\n",
      "Appended 68,430 rows to lockdown_january_2021.csv\n",
      "Appended 500,000 rows to lockdown_january_2021.csv\n",
      "Appended 500,000 rows to lockdown_january_2021.csv\n",
      "Appended 500,000 rows to lockdown_january_2021.csv\n",
      "Appended 500,000 rows to lockdown_january_2021.csv\n",
      "Appended 500,000 rows to lockdown_january_2021.csv\n",
      "Appended 500,000 rows to lockdown_january_2021.csv\n",
      "Appended 500,000 rows to lockdown_january_2021.csv\n",
      "Appended 500,000 rows to lockdown_january_2021.csv\n",
      "Appended 500,000 rows to lockdown_january_2021.csv\n",
      "Appended 212,037 rows to lockdown_february_2021.csv\n",
      "Appended 287,963 rows to lockdown_january_2021.csv\n",
      "Appended 500,000 rows to lockdown_february_2021.csv\n",
      "Appended 500,000 rows to lockdown_february_2021.csv\n",
      "Appended 500,000 rows to lockdown_february_2021.csv\n",
      "Appended 500,000 rows to lockdown_february_2021.csv\n",
      "Appended 500,000 rows to lockdown_february_2021.csv\n",
      "Appended 500,000 rows to lockdown_february_2021.csv\n",
      "Appended 500,000 rows to lockdown_february_2021.csv\n",
      "Appended 500,000 rows to lockdown_february_2021.csv\n",
      "Appended 347,172 rows to lockdown_february_2021.csv\n",
      "Appended 152,828 rows to lockdown_march_2021.csv\n",
      "Appended 500,000 rows to lockdown_march_2021.csv\n",
      "Appended 500,000 rows to lockdown_march_2021.csv\n",
      "Appended 500,000 rows to lockdown_march_2021.csv\n",
      "Appended 500,000 rows to lockdown_march_2021.csv\n",
      "Appended 500,000 rows to lockdown_march_2021.csv\n",
      "Appended 500,000 rows to lockdown_march_2021.csv\n",
      "Appended 500,000 rows to lockdown_march_2021.csv\n",
      "Appended 500,000 rows to lockdown_march_2021.csv\n",
      "Appended 500,000 rows to lockdown_march_2021.csv\n",
      "Appended 43,750 rows to lockdown_april_2021.csv\n",
      "Appended 456,250 rows to lockdown_march_2021.csv\n",
      "Appended 500,000 rows to lockdown_april_2021.csv\n",
      "Appended 500,000 rows to lockdown_april_2021.csv\n",
      "Appended 500,000 rows to lockdown_april_2021.csv\n",
      "Appended 500,000 rows to lockdown_april_2021.csv\n",
      "Appended 500,000 rows to lockdown_april_2021.csv\n",
      "Appended 500,000 rows to lockdown_april_2021.csv\n",
      "Appended 500,000 rows to lockdown_april_2021.csv\n",
      "Appended 500,000 rows to lockdown_april_2021.csv\n",
      "Appended 500,000 rows to lockdown_april_2021.csv\n",
      "Appended 259,534 rows to lockdown_april_2021.csv\n",
      "Appended 240,466 rows to lockdown_may_2021.csv\n",
      "Appended 500,000 rows to lockdown_may_2021.csv\n",
      "Appended 500,000 rows to lockdown_may_2021.csv\n",
      "Appended 500,000 rows to lockdown_may_2021.csv\n",
      "Appended 500,000 rows to lockdown_may_2021.csv\n",
      "Appended 500,000 rows to lockdown_may_2021.csv\n",
      "Appended 500,000 rows to lockdown_may_2021.csv\n",
      "Appended 500,000 rows to lockdown_may_2021.csv\n",
      "Appended 500,000 rows to lockdown_may_2021.csv\n",
      "Appended 500,000 rows to lockdown_may_2021.csv\n",
      "Appended 119,473 rows to lockdown_may_2021.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# File path and output directory\n",
    "file_path = r\"C:\\Users\\athen\\Documents\\GitHub\\TCD_Dissertation\\archive\\periods\\lockdown\\covid_lockdown.csv\"\n",
    "output_dir = r\"C:\\Users\\athen\\Documents\\GitHub\\TCD_Dissertation\\archive\\periods\\lockdown\\months\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "chunksize = 500_000\n",
    "written_files = set()\n",
    "\n",
    "# Process and save each chunk individually\n",
    "for chunk in pd.read_csv(file_path, chunksize=chunksize, parse_dates=[\"DateTime\", \"ServiceDay\"]):\n",
    "    chunk['Month'] = chunk['ServiceDay'].dt.strftime('%B').str.lower()\n",
    "    chunk['Year'] = chunk['ServiceDay'].dt.year\n",
    "\n",
    "    for (year, month), group in chunk.groupby(['Year', 'Month']):\n",
    "        filename = f\"lockdown_{month}_{year}.csv\"\n",
    "        filepath = os.path.join(output_dir, filename)\n",
    "\n",
    "        write_header = filename not in written_files\n",
    "        group.to_csv(filepath, mode='a', header=write_header, index=False)\n",
    "        written_files.add(filename)\n",
    "\n",
    "        print(f\"Appended {len(group):,} rows to {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa08f1a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended 500,000 rows to recovery_june_2021.csv\n",
      "Appended 500,000 rows to recovery_june_2021.csv\n",
      "Appended 500,000 rows to recovery_june_2021.csv\n",
      "Appended 500,000 rows to recovery_june_2021.csv\n",
      "Appended 500,000 rows to recovery_june_2021.csv\n",
      "Appended 500,000 rows to recovery_june_2021.csv\n",
      "Appended 500,000 rows to recovery_june_2021.csv\n",
      "Appended 500,000 rows to recovery_june_2021.csv\n",
      "Appended 500,000 rows to recovery_june_2021.csv\n",
      "Appended 270,064 rows to recovery_july_2021.csv\n",
      "Appended 229,936 rows to recovery_june_2021.csv\n",
      "Appended 500,000 rows to recovery_july_2021.csv\n",
      "Appended 500,000 rows to recovery_july_2021.csv\n",
      "Appended 500,000 rows to recovery_july_2021.csv\n",
      "Appended 500,000 rows to recovery_july_2021.csv\n",
      "Appended 500,000 rows to recovery_july_2021.csv\n",
      "Appended 500,000 rows to recovery_july_2021.csv\n",
      "Appended 500,000 rows to recovery_july_2021.csv\n",
      "Appended 500,000 rows to recovery_july_2021.csv\n",
      "Appended 500,000 rows to recovery_july_2021.csv\n",
      "Appended 419,498 rows to recovery_august_2021.csv\n",
      "Appended 80,502 rows to recovery_july_2021.csv\n",
      "Appended 500,000 rows to recovery_august_2021.csv\n",
      "Appended 500,000 rows to recovery_august_2021.csv\n",
      "Appended 500,000 rows to recovery_august_2021.csv\n",
      "Appended 500,000 rows to recovery_august_2021.csv\n",
      "Appended 500,000 rows to recovery_august_2021.csv\n",
      "Appended 500,000 rows to recovery_august_2021.csv\n",
      "Appended 500,000 rows to recovery_august_2021.csv\n",
      "Appended 500,000 rows to recovery_august_2021.csv\n",
      "Appended 261,061 rows to recovery_august_2021.csv\n",
      "Appended 238,939 rows to recovery_september_2021.csv\n",
      "Appended 500,000 rows to recovery_september_2021.csv\n",
      "Appended 500,000 rows to recovery_september_2021.csv\n",
      "Appended 500,000 rows to recovery_september_2021.csv\n",
      "Appended 500,000 rows to recovery_september_2021.csv\n",
      "Appended 500,000 rows to recovery_september_2021.csv\n",
      "Appended 500,000 rows to recovery_september_2021.csv\n",
      "Appended 500,000 rows to recovery_september_2021.csv\n",
      "Appended 500,000 rows to recovery_september_2021.csv\n",
      "Appended 2,640 rows to recovery_october_2021.csv\n",
      "Appended 497,360 rows to recovery_september_2021.csv\n",
      "Appended 500,000 rows to recovery_october_2021.csv\n",
      "Appended 500,000 rows to recovery_october_2021.csv\n",
      "Appended 500,000 rows to recovery_october_2021.csv\n",
      "Appended 500,000 rows to recovery_october_2021.csv\n",
      "Appended 500,000 rows to recovery_october_2021.csv\n",
      "Appended 500,000 rows to recovery_october_2021.csv\n",
      "Appended 500,000 rows to recovery_october_2021.csv\n",
      "Appended 500,000 rows to recovery_october_2021.csv\n",
      "Appended 500,000 rows to recovery_october_2021.csv\n",
      "Appended 417,686 rows to recovery_november_2021.csv\n",
      "Appended 82,314 rows to recovery_october_2021.csv\n",
      "Appended 500,000 rows to recovery_november_2021.csv\n",
      "Appended 500,000 rows to recovery_november_2021.csv\n",
      "Appended 500,000 rows to recovery_november_2021.csv\n",
      "Appended 500,000 rows to recovery_november_2021.csv\n",
      "Appended 500,000 rows to recovery_november_2021.csv\n",
      "Appended 500,000 rows to recovery_november_2021.csv\n",
      "Appended 500,000 rows to recovery_november_2021.csv\n",
      "Appended 500,000 rows to recovery_november_2021.csv\n",
      "Appended 17,297 rows to recovery_december_2021.csv\n",
      "Appended 482,703 rows to recovery_november_2021.csv\n",
      "Appended 500,000 rows to recovery_december_2021.csv\n",
      "Appended 500,000 rows to recovery_december_2021.csv\n",
      "Appended 500,000 rows to recovery_december_2021.csv\n",
      "Appended 500,000 rows to recovery_december_2021.csv\n",
      "Appended 500,000 rows to recovery_december_2021.csv\n",
      "Appended 500,000 rows to recovery_december_2021.csv\n",
      "Appended 500,000 rows to recovery_december_2021.csv\n",
      "Appended 500,000 rows to recovery_december_2021.csv\n",
      "Appended 500,000 rows to recovery_december_2021.csv\n",
      "Appended 32,173 rows to recovery_december_2021.csv\n",
      "Appended 467,827 rows to recovery_january_2022.csv\n",
      "Appended 500,000 rows to recovery_january_2022.csv\n",
      "Appended 500,000 rows to recovery_january_2022.csv\n",
      "Appended 500,000 rows to recovery_january_2022.csv\n",
      "Appended 500,000 rows to recovery_january_2022.csv\n",
      "Appended 417,583 rows to recovery_january_2022.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# File path and output directory\n",
    "file_path = r\"C:\\Users\\athen\\Documents\\GitHub\\TCD_Dissertation\\archive\\periods\\recovery\\covid_recovery.csv\"\n",
    "output_dir = r\"C:\\Users\\athen\\Documents\\GitHub\\TCD_Dissertation\\archive\\periods\\recovery\\months\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "chunksize = 500_000\n",
    "written_files = set()\n",
    "\n",
    "# Process and save each chunk individually\n",
    "for chunk in pd.read_csv(file_path, chunksize=chunksize, parse_dates=[\"DateTime\", \"ServiceDay\"]):\n",
    "    chunk['Month'] = chunk['ServiceDay'].dt.strftime('%B').str.lower()\n",
    "    chunk['Year'] = chunk['ServiceDay'].dt.year\n",
    "\n",
    "    for (year, month), group in chunk.groupby(['Year', 'Month']):\n",
    "        filename = f\"recovery_{month}_{year}.csv\"\n",
    "        filepath = os.path.join(output_dir, filename)\n",
    "\n",
    "        write_header = filename not in written_files\n",
    "        group.to_csv(filepath, mode='a', header=write_header, index=False)\n",
    "        written_files.add(filename)\n",
    "\n",
    "        print(f\"Appended {len(group):,} rows to {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668bb54b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended 500,000 rows to postcovid_january_2022.csv\n",
      "Appended 500,000 rows to postcovid_january_2022.csv\n",
      "Appended 48,765 rows to postcovid_february_2022.csv\n",
      "Appended 451,235 rows to postcovid_january_2022.csv\n",
      "Appended 500,000 rows to postcovid_february_2022.csv\n",
      "Appended 500,000 rows to postcovid_february_2022.csv\n",
      "Appended 500,000 rows to postcovid_february_2022.csv\n",
      "Appended 500,000 rows to postcovid_february_2022.csv\n",
      "Appended 500,000 rows to postcovid_february_2022.csv\n",
      "Appended 500,000 rows to postcovid_february_2022.csv\n",
      "Appended 500,000 rows to postcovid_february_2022.csv\n",
      "Appended 500,000 rows to postcovid_february_2022.csv\n",
      "Appended 280,967 rows to postcovid_february_2022.csv\n",
      "Appended 219,033 rows to postcovid_march_2022.csv\n",
      "Appended 500,000 rows to postcovid_march_2022.csv\n",
      "Appended 500,000 rows to postcovid_march_2022.csv\n",
      "Appended 500,000 rows to postcovid_march_2022.csv\n",
      "Appended 500,000 rows to postcovid_march_2022.csv\n",
      "Appended 500,000 rows to postcovid_march_2022.csv\n",
      "Appended 500,000 rows to postcovid_march_2022.csv\n",
      "Appended 500,000 rows to postcovid_march_2022.csv\n",
      "Appended 500,000 rows to postcovid_march_2022.csv\n",
      "Appended 150,264 rows to postcovid_april_2022.csv\n",
      "Appended 349,736 rows to postcovid_march_2022.csv\n",
      "Appended 500,000 rows to postcovid_april_2022.csv\n",
      "Appended 500,000 rows to postcovid_april_2022.csv\n",
      "Appended 500,000 rows to postcovid_april_2022.csv\n",
      "Appended 500,000 rows to postcovid_april_2022.csv\n",
      "Appended 500,000 rows to postcovid_april_2022.csv\n",
      "Appended 500,000 rows to postcovid_april_2022.csv\n",
      "Appended 500,000 rows to postcovid_april_2022.csv\n",
      "Appended 500,000 rows to postcovid_april_2022.csv\n",
      "Appended 425,950 rows to postcovid_april_2022.csv\n",
      "Appended 74,050 rows to postcovid_may_2022.csv\n",
      "Appended 500,000 rows to postcovid_may_2022.csv\n",
      "Appended 500,000 rows to postcovid_may_2022.csv\n",
      "Appended 500,000 rows to postcovid_may_2022.csv\n",
      "Appended 500,000 rows to postcovid_may_2022.csv\n",
      "Appended 500,000 rows to postcovid_may_2022.csv\n",
      "Appended 500,000 rows to postcovid_may_2022.csv\n",
      "Appended 500,000 rows to postcovid_may_2022.csv\n",
      "Appended 500,000 rows to postcovid_may_2022.csv\n",
      "Appended 500,000 rows to postcovid_may_2022.csv\n",
      "Appended 56,984 rows to postcovid_june_2022.csv\n",
      "Appended 443,016 rows to postcovid_may_2022.csv\n",
      "Appended 500,000 rows to postcovid_june_2022.csv\n",
      "Appended 500,000 rows to postcovid_june_2022.csv\n",
      "Appended 500,000 rows to postcovid_june_2022.csv\n",
      "Appended 500,000 rows to postcovid_june_2022.csv\n",
      "Appended 500,000 rows to postcovid_june_2022.csv\n",
      "Appended 500,000 rows to postcovid_june_2022.csv\n",
      "Appended 500,000 rows to postcovid_june_2022.csv\n",
      "Appended 500,000 rows to postcovid_june_2022.csv\n",
      "Appended 500,000 rows to postcovid_june_2022.csv\n",
      "Appended 439,233 rows to postcovid_july_2022.csv\n",
      "Appended 60,767 rows to postcovid_june_2022.csv\n",
      "Appended 500,000 rows to postcovid_july_2022.csv\n",
      "Appended 500,000 rows to postcovid_july_2022.csv\n",
      "Appended 500,000 rows to postcovid_july_2022.csv\n",
      "Appended 500,000 rows to postcovid_july_2022.csv\n",
      "Appended 500,000 rows to postcovid_july_2022.csv\n",
      "Appended 500,000 rows to postcovid_july_2022.csv\n",
      "Appended 500,000 rows to postcovid_july_2022.csv\n",
      "Appended 500,000 rows to postcovid_july_2022.csv\n",
      "Appended 62,664 rows to postcovid_august_2022.csv\n",
      "Appended 437,336 rows to postcovid_july_2022.csv\n",
      "Appended 500,000 rows to postcovid_august_2022.csv\n",
      "Appended 500,000 rows to postcovid_august_2022.csv\n",
      "Appended 500,000 rows to postcovid_august_2022.csv\n",
      "Appended 500,000 rows to postcovid_august_2022.csv\n",
      "Appended 500,000 rows to postcovid_august_2022.csv\n",
      "Appended 500,000 rows to postcovid_august_2022.csv\n",
      "Appended 500,000 rows to postcovid_august_2022.csv\n",
      "Appended 500,000 rows to postcovid_august_2022.csv\n",
      "Appended 500,000 rows to postcovid_august_2022.csv\n",
      "Appended 500,000 rows to postcovid_august_2022.csv\n",
      "Appended 27,320 rows to postcovid_august_2022.csv\n",
      "Appended 472,680 rows to postcovid_september_2022.csv\n",
      "Appended 500,000 rows to postcovid_september_2022.csv\n",
      "Appended 500,000 rows to postcovid_september_2022.csv\n",
      "Appended 500,000 rows to postcovid_september_2022.csv\n",
      "Appended 500,000 rows to postcovid_september_2022.csv\n",
      "Appended 500,000 rows to postcovid_september_2022.csv\n",
      "Appended 500,000 rows to postcovid_september_2022.csv\n",
      "Appended 500,000 rows to postcovid_september_2022.csv\n",
      "Appended 500,000 rows to postcovid_september_2022.csv\n",
      "Appended 500,000 rows to postcovid_september_2022.csv\n",
      "Appended 225,456 rows to postcovid_october_2022.csv\n",
      "Appended 274,544 rows to postcovid_september_2022.csv\n",
      "Appended 500,000 rows to postcovid_october_2022.csv\n",
      "Appended 500,000 rows to postcovid_october_2022.csv\n",
      "Appended 500,000 rows to postcovid_october_2022.csv\n",
      "Appended 500,000 rows to postcovid_october_2022.csv\n",
      "Appended 500,000 rows to postcovid_october_2022.csv\n",
      "Appended 500,000 rows to postcovid_october_2022.csv\n",
      "Appended 500,000 rows to postcovid_october_2022.csv\n",
      "Appended 112,616 rows to postcovid_october_2022.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# File path and output directory\n",
    "file_path = r\"C:\\Users\\athen\\Documents\\GitHub\\TCD_Dissertation\\archive\\periods\\postcovid\\post_covid.csv\"\n",
    "output_dir = r\"C:\\Users\\athen\\Documents\\GitHub\\TCD_Dissertation\\archive\\periods\\postcovid\\months\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "chunksize = 500_000\n",
    "written_files = set()\n",
    "\n",
    "# Process and save each chunk individually\n",
    "for chunk in pd.read_csv(file_path, chunksize=chunksize, parse_dates=[\"DateTime\", \"ServiceDay\"]):\n",
    "    chunk['Month'] = chunk['ServiceDay'].dt.strftime('%B').str.lower()\n",
    "    chunk['Year'] = chunk['ServiceDay'].dt.year\n",
    "\n",
    "    for (year, month), group in chunk.groupby(['Year', 'Month']):\n",
    "        filename = f\"postcovid_{month}_{year}.csv\"\n",
    "        filepath = os.path.join(output_dir, filename)\n",
    "\n",
    "        write_header = filename not in written_files\n",
    "        group.to_csv(filepath, mode='a', header=write_header, index=False)\n",
    "        written_files.add(filename)\n",
    "\n",
    "        print(f\"Appended {len(group):,} rows to {filename}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dissertation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
